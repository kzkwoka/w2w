{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/tscratch/people/plgkingak'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"weights2weights/weights_datasets\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dimensions = torch.load(f\"{path}/weight_dimensions.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.DataFrame(weight_dimensions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.lora_A.weight</th>\n",
       "      <td>(768,)</td>\n",
       "      <td>(1, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (320, 1)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (320, 1)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "...                                                    ...       ...\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (1, 320)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (768,)  (1, 768)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"use\"] = 0\n",
    "dim_df.loc[dim_df.index.str.contains(\"mid_block\"), \"use\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df.use.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"lengths\"] = [a.numel() for a,_ in list(weight_dimensions.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"start\"] = dim_df.lengths.cumsum().shift(fill_value=0)\n",
    "dim_df[\"end\"] = dim_df.start + dim_df.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>use</th>\n",
       "      <th>lengths</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>35968</td>\n",
       "      <td>37248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>37248</td>\n",
       "      <td>38528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>38528</td>\n",
       "      <td>39808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>39808</td>\n",
       "      <td>41088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>41088</td>\n",
       "      <td>42368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>42368</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.lora_A.weight</th>\n",
       "      <td>(768,)</td>\n",
       "      <td>(1, 768)</td>\n",
       "      <td>1</td>\n",
       "      <td>768</td>\n",
       "      <td>43648</td>\n",
       "      <td>44416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>44416</td>\n",
       "      <td>45696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0          1  use  \\\n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...   (768,)   (1, 768)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "\n",
       "                                                    lengths  start    end  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  35968  37248  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  37248  38528  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  38528  39808  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  39808  41088  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  41088  42368  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  42368  43648  \n",
       "base_model.model.mid_block.attentions.0.transfo...      768  43648  44416  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  44416  45696  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df[dim_df.use == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([np.arange(row.start, row.end) for _, row in dim_df[dim_df.use == 1].iterrows()])\n",
    "len(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(f\"{path}/identities/all_weights.pt\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(weights[:,indices], f'{path}/mid_block.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(f'{path}/mid_block.pt', torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629e4adce756427db8ea32f341c93a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/6 shards):   0%|          | 0/64974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset.from_dict({\"data\":dataset}).save_to_disk(f'{path}/mid_block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_dict({\"data\":dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['data'],\n",
       "    num_rows: 64974\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[0][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
