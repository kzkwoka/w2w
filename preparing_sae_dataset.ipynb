{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/tscratch/people/plgkingak'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"weights2weights/weights_datasets\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dimensions = torch.load(f\"{path}/weight_dimensions.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.DataFrame(weight_dimensions).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(1, 320)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.lora_A.weight</th>\n",
       "      <td>(768,)</td>\n",
       "      <td>(1, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.lora_B.weight</th>\n",
       "      <td>(320,)</td>\n",
       "      <td>(320, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (320, 1)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (320, 1)\n",
       "base_model.model.down_blocks.0.attentions.0.tra...  (320,)  (1, 320)\n",
       "...                                                    ...       ...\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (1, 320)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (768,)  (1, 768)\n",
       "base_model.model.up_blocks.3.attentions.2.trans...  (320,)  (320, 1)\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"use\"] = 0\n",
    "dim_df.loc[dim_df.index.str.contains(\"mid_block\"), \"use\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df.use.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"lengths\"] = [a.numel() for a,_ in list(weight_dimensions.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df[\"start\"] = dim_df.lengths.cumsum().shift(fill_value=0)\n",
    "dim_df[\"end\"] = dim_df.start + dim_df.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>use</th>\n",
       "      <th>lengths</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>35968</td>\n",
       "      <td>37248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>37248</td>\n",
       "      <td>38528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>38528</td>\n",
       "      <td>39808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>39808</td>\n",
       "      <td>41088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.lora_A.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1, 1280)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>41088</td>\n",
       "      <td>42368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>42368</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.lora_A.weight</th>\n",
       "      <td>(768,)</td>\n",
       "      <td>(1, 768)</td>\n",
       "      <td>1</td>\n",
       "      <td>768</td>\n",
       "      <td>43648</td>\n",
       "      <td>44416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_model.model.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.lora_B.weight</th>\n",
       "      <td>(1280,)</td>\n",
       "      <td>(1280, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1280</td>\n",
       "      <td>44416</td>\n",
       "      <td>45696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0          1  use  \\\n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1, 1280)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...   (768,)   (1, 768)    1   \n",
       "base_model.model.mid_block.attentions.0.transfo...  (1280,)  (1280, 1)    1   \n",
       "\n",
       "                                                    lengths  start    end  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  35968  37248  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  37248  38528  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  38528  39808  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  39808  41088  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  41088  42368  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  42368  43648  \n",
       "base_model.model.mid_block.attentions.0.transfo...      768  43648  44416  \n",
       "base_model.model.mid_block.attentions.0.transfo...     1280  44416  45696  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df[dim_df.use == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9728"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([np.arange(row.start, row.end) for _, row in dim_df[dim_df.use == 1].iterrows()])\n",
    "len(indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(f\"{path}/identities/all_weights.pt\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(weights[:,indices], f'{path}/mid_block.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(f'{path}/mid_block.pt', torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_dict({\"data\":dataset}).save_to_disk(f'{path}/mid_block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_dict({\"data\":dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d[0][\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(f\"{path}/identities/all_weights.pt\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = torch.randperm(weights.size(0))[:10]\n",
    "sampled_rows = weights[random_indices]\n",
    "\n",
    "torch.save(sampled_rows, f'{path}/evaluation_samples.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blondes (and brunettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "df = torch.load('/net/tscratch/people/plgkingak/weights2weights/files/identity_df.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blondes = df.loc[df[\"Blond_Hair\"] == 1]\n",
    "brunettes = df.loc[df[\"Black_Hair\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blondes.sample(n=2000, random_state=42)\n",
    "brunettes.sample(n=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(f\"{path}/identities/all_weights.pt\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blonde_weights = weights[blondes.sample(n=2000, random_state=42).index]\n",
    "blonde_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(blonde_weights.clone(), f\"{path}/blondes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunette_weights = weights[brunettes.sample(n=2000, random_state=42).index]\n",
    "brunette_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(brunette_weights.clone(), f\"{path}/brunettes.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "df = torch.load('/net/tscratch/people/plgkingak/weights2weights/files/identity_df.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(f\"{path}/identities/all_weights.pt\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = df.index.str.split(\".\").str[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64974, 99648])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check values\n",
    "\n",
    "Maybe some columns are all 0, or all the same value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcnts = []\n",
    "ucnts = []\n",
    "zero = (weights == 0)\n",
    "for i in range(weights.shape[1]):\n",
    "    zcnts.append(zero[:,i].sum().item())\n",
    "    value_counts = {}\n",
    "    for val in weights[:, i]:\n",
    "        val_item = val.item()\n",
    "        if val_item in value_counts:\n",
    "            value_counts[val_item] += 1\n",
    "        else:\n",
    "            value_counts[val_item] = 1\n",
    "    ucnts.append(max(value_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(zcnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ucnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = weights.min()\n",
    "max_val = weights.max()\n",
    "# outmap = (weights - outmap_min) / (outmap_max - outmap_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = weights.mean()\n",
    "std = weights.std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights.sub_(min_val).div_(max_val - min_val).mul_(2).sub_(1)\n",
    "weights.sub_(mean).div_(std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"rescaled\" # \"single\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(weights):\n",
    "    filename = f\"{path}/{name}/{filenames[i]}.pt\"\n",
    "    torch.save(row.clone(), filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir =  f\"{path}/{name}/\"\n",
    "file_list = sorted(os.listdir(data_dir)) \n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        tensor = torch.load(file_path)  # Load tensor lazily\n",
    "        yield {\"filename\": filename, \"data\": tensor.cpu().numpy()}  # Convert tensor to NumPy\n",
    "        \n",
    "dataset = Dataset.from_generator(data_generator, cache_dir=f\"{path}/.cache\")\n",
    "dataset.save_to_disk(f\"{path}/full_rescaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dataset[2][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
